# âš¡ Real-Time Kafka Streaming Pipeline

A production-grade, containerized real-time data pipeline for ingesting, validating, and storing wind turbine telemetry using Apache Kafka, Python, PostgreSQL, and Prometheus/Grafana. This project is fully CI/CD enabled and structured to reflect modern industry standards in data engineering.

## ğŸš€ Overview

This pipeline simulates a real-world wind turbine monitoring system:

- Simulated sensor data is produced and streamed via Kafka.
- A Kafka consumer receives, validates, and stores the data in PostgreSQL.
- Pandera enforces schema validation for data quality.
- Prometheus scrapes metrics exposed by the consumer.
- Grafana visualizes real-time health of the pipeline.
- GitHub Actions powers continuous integration with automated linting and testing.

## ğŸ§± Architecture

Producer â†’ Kafka â†’ Consumer â†’ PostgreSQL  
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ†³ Schema Validation (Pandera)  
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ†³ Monitoring (Prometheus + Grafana)

## ğŸ›  Tech Stack

Messaging: Apache Kafka, Zookeeper  
Data Simulation: Python Kafka Producer  
Ingestion & Logic: Python Consumer, Pandera Schema Validation  
Storage: PostgreSQL  
Monitoring: Prometheus, Grafana  
Containerization: Docker, Docker Compose  
CI/CD: GitHub Actions, flake8, pytest  

## âœ… Features

- Real-time message streaming with Kafka
- Pandera-based schema enforcement
- PostgreSQL persistence for clean, validated records
- Prometheus metrics with Grafana dashboards
- Flake8 linting and Pytest unit tests
- GitHub Actions CI pipeline for robust automation
- Modular, production-grade folder structure

## ğŸ“¦ Getting Started

### 1. Requirements

- Docker & Docker Compose
- Python 3.11+ (optional for local test execution)
- Free ports: 9092, 5432, 9090, 3000

### 2. Setup & Run

Clone the repo and launch the entire pipeline:

```bash
git clone https://github.com/vk20001/realtime-wind-streaming-pipeline.git
cd realtime-wind-streaming-pipeline
docker compose up --build
```

### 3. Access Points

Grafana: http://localhost:3000  
Prometheus: http://localhost:9090  
PostgreSQL: localhost:5432 (use DBeaver or psql)  
Kafka Broker: localhost:9092  

## ğŸ”¬ Testing & Linting

Run locally:  
```bash
pytest consumer/tests/
flake8 .
```

CI/CD via GitHub Actions ensures automated testing and formatting on every push.

## ğŸ“Š Observability Metrics

Prometheus metrics exposed by the consumer:  
- `messages_total`: All Kafka messages received  
- `messages_valid`: Messages that passed validation  
- `messages_invalid`: Messages that failed validation  

These are visualized in Grafana with live updates.

## ğŸ“ Project Structure

```
consumer/              â†’ Kafka consumer and schema logic
â””â”€â”€ tests/             â†’ Unit and integration tests
producer/              â†’ Kafka producer for simulated turbine data
monitoring/            â†’ Prometheus & Grafana configs
scripts/               â†’ Utility scripts
.github/workflows/     â†’ GitHub Actions CI workflow
docker-compose.yml     â†’ Service orchestration
.flake8                â†’ Linting configuration
.env                   â†’ Environment variables
.gitignore             â†’ Ignore unnecessary files
```

## ğŸŒ± Future Enhancements

- Add Kafka UI (e.g., Kafdrop)
- Integrate logging with Loki or DataDog
- Container health checks and restart policies
- Kubernetes + Helm deployment (GKE or EKS)
- TLS & security hardening

## ğŸ‘©â€ğŸ’» Author

**Vaishnavi K.**  
Masterâ€™s in Applied Data Science & Analytics  
Built with love, logic, and a stubborn Kafka broker.  
GitHub: https://github.com/vk20001


